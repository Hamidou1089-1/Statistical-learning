{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecfe602-4165-410f-b1ab-dc8a517e32db",
   "metadata": {},
   "source": [
    "### ENSIMAG ‚Äì Grenoble INP ‚Äì UGA - Academic year 2024-2025\n",
    "# Introduction to Statistical Learning and Applications ([website](https://github.com/ISLA-Grenoble/2025-main))\n",
    "\n",
    "- Pedro L. C. Rodrigues -- `pedro.rodrigues@inria.fr`\n",
    "\n",
    "- Alexandre Wendling -- `alexandre.wendling@univ-grenoble-alpes.fr`\n",
    "\n",
    "***\n",
    "\n",
    "### ‚ö†Ô∏è General guidelines for TPs\n",
    "\n",
    "Each team shall upload its report on [Teide](https://teide.ensimag.fr/) before the deadline indicated at the course website. Please\n",
    "**include the name of all members** of the team on top of your report.\n",
    "The report should contain graphical representations and explanatory text. For each graph, axis names should be provided as well\n",
    "as a legend when it is appropriate. Figures should be explained by a few sentences in the text. Answer to\n",
    "the questions in order and refer to the question number in your report. Computations and\n",
    "graphics have to be performed in `python`. The report should be written as a jupyter notebook. This is a file format that allows users to format documents containing text written in markdown and `python` instructions. You should include all of the `python` instructions that you have used in the document so that it may be possible to replicate your results.\n",
    "\n",
    "***\n",
    "\n",
    "# üñ•Ô∏è TP3: Benchmarking classification methods\n",
    "\n",
    "In this TP, we will be using mostly the packages `numpy`, `sklearn`, and `matplotlib`.\n",
    "\n",
    "## ‚ñ∂Ô∏è Part 1\n",
    "\n",
    "Consider a simulated dataset generated as follows:\n",
    "\n",
    "**-- (Step 1)** For each data point $i$, sample its label from a Bernoulli distribution $y_i \\sim \\mathcal{B}(p)$, i.e. $y_i = 1$ with probability $p$ and $y_i = 0$ with probability $1-p$. Note that to sample a random variable $B$ from $\\mathcal{B}(p)$ you can first sample $U$ from an uniform distribution as in `U = numpy.random.rand()` and then note that $B = \\mathbf{1}(U < p)$ where $\\mathbf{1}(\\cdot)$ is an indicator function.\n",
    "\n",
    "**-- (Step 2)** Then, depending on the label $y_i \\in \\{0, 1\\}$ the associated data point $\\mathbf{x}_i \\in \\mathbb{R}^2$ is sampled as follows:\n",
    "\n",
    "$$\n",
    "  \\mathbf{x}_i \\mid y_i = 0 \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0, \\boldsymbol{\\Sigma}_0) \\quad \\text{and} \\quad \\mathbf{x}_i \\mid y_i = 1 \\sim \\mathcal{N}(\\boldsymbol{\\mu}_1, \\boldsymbol{\\Sigma}_1)\n",
    "$$\n",
    "\n",
    "where $\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$ is a multivariate normal distribution with mean $\\boldsymbol{\\mu}$ and covariance matrix $\\boldsymbol{\\Sigma}$ with pdf\n",
    "\n",
    "$$\n",
    "p_{\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})}(x) = \\dfrac{1}{2\\pi\\sqrt{\\det{\\boldsymbol{\\Sigma}}}}\\exp\\left(-\\dfrac{1}{2}\\big(\\boldsymbol{x}-\\boldsymbol{\\mu}\\big)^\\top \\boldsymbol{\\Sigma}^{-1}\\big(\\boldsymbol{x}-\\boldsymbol{\\mu}\\big)\\right)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\boldsymbol{\\mu}_0 = \\left[\\begin{array}{c}0 \\\\ 0\\end{array}\\right] \\quad \\boldsymbol{\\mu}_1 = \\left[\\begin{array}{c}\\varepsilon \\\\ 0\\end{array}\\right] \\quad \\boldsymbol{\\Sigma}_0 = \\left[\\begin{array}{cc}0.5 & 0 \\\\ 0 & 0.5\\end{array}\\right] \\quad \\boldsymbol{\\Sigma}_1 = \\left[\\begin{array}{cc}0.4 & 0 \\\\ 0 & 0.4\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Note that to sample a $p$-dimensional vector $\\mathbf{x}$ from $\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$, you can use function `numpy.random.multivariate_normal`.\n",
    "\n",
    "We will denote a set of $N$ data points $\\{(\\mathbf{x}_i, y_i)\\}_{i = 1}^N$ simulated with $\\varepsilon$ and $p$ as $\\mathcal{D}(N \\mid \\varepsilon, p)$. \n",
    "\n",
    "Define two datasets:\n",
    "$$\n",
    "\\mathcal{D}_\\text{train} = \\mathcal{D}(50 \\mid 1, 0.30) \\quad \\text{and} \\quad \\mathcal{D}_{\\text{test}} = \\mathcal{D}(1000 \\mid 1, 0.30)~.\n",
    "$$\n",
    "\n",
    "**(a)** Plot the data points in $\\mathcal{D}_\\text{train} \\cup \\mathcal{D}_\\text{test}$ using different colors to indicate the classes of each data point and different pointing symbols to indicate whether a point is from the train or test set. You should use `matplotlib`'s funciton for scatterplots. Remember to always include a legend in your figure.\n",
    "\n",
    "**(b)** What is the mathematical expression for the optimal Bayes classifier in this setting? And for its boundary region? Remember that the Bayes classifier can be written in terms of the ratio of $\\text{Prob}(Y = 1 \\mid \\mathbf{x})$ over $\\text{Prob}(Y = 0 \\mid \\mathbf{x})$ and that the values of $\\mathbf{x} \\in \\mathbb{R}^2$ for which this ratio is 1 are those defining its boundary.\n",
    "\n",
    "**(c)** Implement the Bayes classifier for this setup using scikit-learn's API as explained [here](https://scikit-learn.org/stable/developers/develop.html). Use your implementation to estimate the error of the Bayes classifier on the samples from $\\mathcal{D}(10000 \\mid 0.5, 0.3)$. How would you expect your results to change for other values of $\\varepsilon$? Plot a curve showing how the Bayes error rate changes for different choices $\\varepsilon$ (note that you will have to generate new datasets for this).\n",
    "\n",
    "**(d)** Given the structure of the model generating the datasets, which classifier presented in our lectures seems to be the most adequate? Justify your answer in terms of the assumptions behind the construction of each classifier.\n",
    "\n",
    "**(e)** Using `sklearn`, train a LDA, a QDA, and a logistic regression classifier on $\\mathcal{D}_\\text{train}$ and estimate their errors on the samples from $\\mathcal{D}_\\text{test}$. How do their errors compare to the value obtained in (c)? Can we expect the gap between the Bayes error rate and test error for each classifier change when the number of samples in $\\mathcal{D}_{\\text{train}}$ in change? Justify your answer both theoretically and empirically.\n",
    "\n",
    "**(f)** Consider a new test set defined as $\\mathcal{D}'_\\text{test} = \\mathcal{D}(1000 \\mid 0.5, 0.7)$. Use the same classifiers trained in (e) and estimate their new test errors. Do you observe any difference in the results? Can you explain what is happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fddcc4-00bc-4b3e-87b3-ed236c850ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a44482e-3638-4de4-8d02-52903f49ef1f",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Part 2 \n",
    "\n",
    "In this part, we will consider a simulated benchmark similar to that from [Section 4.5.2 in James et al](https://www.statlearning.com/) presented and discussed in class. Our benchmark will compare the performance of four classifiers under three different scenarios.\n",
    "\n",
    "### -- Scenario 1\n",
    "The observations for this scenario are generated as per:\n",
    "\n",
    "$$\n",
    "\\{(\\mathbf{x}_i, y_i)\\}_{i = 1}^{2N} = \\{(\\mathbf{x}_i, 0)\\}_{i = 1}^{N} \\cup \\{(\\mathbf{x}_i, 1)\\}_{i = 1}^{N}\n",
    "$$\n",
    "with\n",
    "$$\n",
    "\\mathbf{x}_i | y_i = 0 \\sim \\mathcal{N}(\\mathbf{\\mu}_0, \\mathbf{\\Sigma}_0) \\quad \\text{with} \\quad \\mathbf{\\mu}_0 = \\left[\\begin{array}{c}0 \\\\ 0\\end{array}\\right] \\quad \\text{and} \\quad \\mathbf{\\Sigma}_0 = \\left[\\begin{array}{cc}1 & 0 \\\\ 0 & 2\\end{array}\\right]\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\mathbf{x}_i | y_i = 1 \\sim \\mathcal{N}(\\mathbf{\\mu}_1, \\mathbf{\\Sigma}_1) \\quad \\text{with} \\quad \\mathbf{\\mu}_1 = \\left[\\begin{array}{c}1 \\\\ 1\\end{array}\\right] \\quad \\text{and} \\quad \\mathbf{\\Sigma}_1 = \\left[\\begin{array}{cc}1 & 0 \\\\ 0 & 2\\end{array}\\right]~.\n",
    "$$\n",
    "\n",
    "The training set always have $N=20$ and the test set $N=5000$. \n",
    "\n",
    "**(a)** Using `sklearn`, compare the performances of LDA, logistic regression, Gaussian naive Bayes, and QDA in this scenario. For this, you should generate 100 pairs of training-test datasets and evaluate the test errors for each of the classifiers. Use `matplotlib.pyplot.boxplot` to display the results for each of the classifiers along the different realizations. Explain the differences of the performances in terms of the assumptions of each classifier and the structure of the data generating mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29680d0-2610-4eb2-beaa-d5edfbbc4b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38597dce-b396-4b7d-aeaa-833a9612a28b",
   "metadata": {},
   "source": [
    "### -- Scenario 2\n",
    "The observations for this scenario are generated as per:\n",
    "\n",
    "$$\n",
    "\\{(\\mathbf{x}_i, y_i)\\}_{i = 1}^{2N} = \\{(\\mathbf{x}_i, 0)\\}_{i = 1}^{N} \\cup \\{(\\mathbf{x}_i, 1)\\}_{i = 1}^{N}\n",
    "$$\n",
    "with\n",
    "$$\n",
    "\\mathbf{x}_i | y_i = 0 \\sim \\mathcal{N}(\\mathbf{\\mu}_0, \\mathbf{\\Sigma}_0) \\quad \\text{with} \\quad \\mathbf{\\mu}_0 = \\left[\\begin{array}{c}0 \\\\ 0\\end{array}\\right] \\quad \\text{and} \\quad \\mathbf{\\Sigma}_0 = \\left[\\begin{array}{cc}1 & -0.7 \\\\ -0.7 & 2\\end{array}\\right]\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\mathbf{x}_i | y_i = 1 \\sim \\mathcal{N}(\\mathbf{\\mu}_1, \\mathbf{\\Sigma}_1) \\quad \\text{with} \\quad \\mathbf{\\mu}_1 = \\left[\\begin{array}{c}1 \\\\ 1\\end{array}\\right] \\quad \\text{and} \\quad \\mathbf{\\Sigma}_1 = \\left[\\begin{array}{cc}1 & -0.7 \\\\ -0.7 & 2\\end{array}\\right]~.\n",
    "$$\n",
    "\n",
    "The training set always have $N=20$ and the test set $N=5000$. \n",
    "\n",
    "**(b)** Perform the same comparison as done for Scenario 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ecfae-cfda-4364-adc0-01a72d28cc0a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "712aacb5-27ca-4a1e-a328-39c32071d048",
   "metadata": {},
   "source": [
    "### -- Scenario 3\n",
    "The observations for this scenario are generated as per:\n",
    "\n",
    "$$\n",
    "\\{(\\mathbf{x}_i, y_i)\\}_{i = 1}^{2N} = \\{(\\mathbf{x}_i, 0)\\}_{i = 1}^{N} \\cup \\{(\\mathbf{x}_i, 1)\\}_{i = 1}^{N}\n",
    "$$\n",
    "with\n",
    "$$\n",
    "\\mathbf{x}_i | y_i = 0 \\sim \\mathcal{N}(\\mathbf{\\mu}_0, \\mathbf{\\Sigma}_0) \\quad \\text{with} \\quad \\mathbf{\\mu}_0 = \\left[\\begin{array}{c}0 \\\\ 0\\end{array}\\right] \\quad \\text{and} \\quad \\mathbf{\\Sigma}_0 = \\left[\\begin{array}{cc}1 & -0.7 \\\\ -0.7 & 2\\end{array}\\right]\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\mathbf{x}_i | y_i = 1 \\sim \\mathcal{N}(\\mathbf{\\mu}_1, \\mathbf{\\Sigma}_1) \\quad \\text{with} \\quad \\mathbf{\\mu}_1 = \\left[\\begin{array}{c}1 \\\\ 1\\end{array}\\right] \\quad \\text{and} \\quad \\mathbf{\\Sigma}_1 = \\left[\\begin{array}{cc}1 & +0.7 \\\\ +0.7 & 2\\end{array}\\right]~.\n",
    "$$\n",
    "\n",
    "The training set always have $N=20$ and the test set $N=5000$. \n",
    "\n",
    "**(c)** Perform the same comparison as done for Scenarios 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df214b-359b-482c-a9b0-58eaac2c8659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23b24737-191a-4295-8641-05581390b568",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Exercise 6: Conclusion\n",
    "\n",
    "Propose a conclusion to your study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7494e5-677d-4076-b430-cd1cd5138a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isla2025",
   "language": "python",
   "name": "isla2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
